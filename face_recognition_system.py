# -*- coding: utf-8 -*-
"""Face_Recognition_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oItARvuSOsri_dG8E7TRUAdqRhk8IPxS
"""

# =============================================
# üî• ADVANCED FACE RECOGNITION SYSTEM - COLAB (AGE REMOVED, GENDER FIXED)
# =============================================

!pip install -q deepface opencv-python matplotlib pandas numpy

import cv2
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from deepface import DeepFace
from PIL import Image
from google.colab import files
from datetime import datetime

# -------------------------------
# Setup folders & attendance file
# -------------------------------
os.makedirs("database", exist_ok=True)
ATTENDANCE_FILE = "attendance.csv"

if not os.path.exists(ATTENDANCE_FILE):
    pd.DataFrame(columns=["Name", "Time"]).to_csv(ATTENDANCE_FILE, index=False)

# -------------------------------
# Attendance marker
# -------------------------------
def mark_attendance(name):
    df = pd.read_csv(ATTENDANCE_FILE)
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    if name not in df["Name"].values:
        df.loc[len(df)] = [name, now]
        df.to_csv(ATTENDANCE_FILE, index=False)
        print(f"‚úî Attendance Marked for {name} at {now}")
    else:
        print(f"‚ö† {name} already marked.")

# -------------------------------
# Show image helper
# -------------------------------
def show_img(path, title=""):
    img = cv2.imread(path)
    if img is None:
        print("Unable to read", path); return
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(5,5))
    if title:
        plt.title(title)
    plt.imshow(img)
    plt.axis("off")
    plt.show()

# -------------------------------
# Upload database images
# -------------------------------
print("üìÅ Upload known person images (database). You can upload many files at once.")
upload_db = files.upload()
for name in upload_db.keys():
    os.rename(name, f"database/{name}")
    print("‚Üí Added to database:", name)

print("üìÇ Database files:", os.listdir("database"))

# -------------------------------
# Upload test image
# -------------------------------
print("\nüìÅ Upload test image to identify")
upload_test = files.upload()
test_img = list(upload_test.keys())[0]
print("Test image:", test_img)
show_img(test_img, "Test Image")

# -------------------------------
# 1-N Recognition (DeepFace.find)
# -------------------------------
print("\nüîé Running FaceNet search (1-N matching)...")
results = DeepFace.find(
    img_path=test_img,
    db_path="database",
    model_name="Facenet",
    enforce_detection=False
)

# DeepFace may return a list containing a DataFrame
df = results[0] if isinstance(results, list) else results

if df.shape[0] == 0:
    print("‚ùå No match found in database.")
else:
    print("\nüéØ MATCHES (top results):")
    display(df.head())

    best_match = df.iloc[0]
    match_path = best_match["identity"]
    distance = best_match["distance"]
    confidence = max(0, 100 - distance * 100)
    person_name = os.path.splitext(os.path.basename(match_path))[0]

    print(f"\n‚≠ê‚≠ê BEST MATCH: {person_name} ({confidence:.1f}% confidence, distance={distance:.4f})")

    # mark attendance for best match
    mark_attendance(person_name)

    # show side-by-side
    fig, ax = plt.subplots(1, 2, figsize=(10,5))
    ax[0].set_title("Test Image")
    ax[0].imshow(Image.open(test_img))
    ax[0].axis("off")

    ax[1].set_title(f"Best Match ({confidence:.1f}%)")
    ax[1].imshow(Image.open(match_path))
    ax[1].axis("off")
    plt.show()

# -------------------------------
# Advanced analysis: gender + emotion (AGE REMOVED)
# -------------------------------
print("\nüß† ADVANCED ANALYSIS (gender + emotion only)")

analysis = DeepFace.analyze(
    img_path=test_img,
    actions=['gender','emotion'],   # age removed
    enforce_detection=False
)

# DeepFace.analyze often returns a list ‚Äî normalize it
if isinstance(analysis, list):
    analysis = analysis[0]

# Gender handling: sometimes a dict of probabilities, sometimes a text label.
raw_gender = analysis.get('gender', None)

if isinstance(raw_gender, dict):
    # pick the label with highest probability
    gender_label = max(raw_gender, key=raw_gender.get)
    gender_conf = raw_gender[gender_label]
    # gender_conf may be numpy float32; convert to float *100 for %
    try:
        gender_conf_pct = float(gender_conf) * 100
    except:
        gender_conf_pct = float(gender_conf)
else:
    # If it's already a label (string), use it; try to find any probability field
    gender_label = raw_gender
    # DeepFace may also provide 'gender' probability under analysis['gender'], but if not, we set to None
    gender_conf_pct = None

emotion_label = analysis.get('dominant_emotion', None)

# Print results (age omitted)
if gender_conf_pct is None:
    print(f"Gender: {gender_label}")
else:
    print(f"Gender: {gender_label} ({gender_conf_pct:.2f}%)")

print(f"Emotion: {emotion_label}")

# -------------------------------
# Face detection + bounding boxes
# -------------------------------
print("\nüì¶ Detecting faces and drawing bounding boxes...")
faces = DeepFace.extract_faces(
    img_path=test_img,
    detector_backend="opencv",
    enforce_detection=False
)

img = cv2.imread(test_img)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

if not faces:
    print("No faces extracted.")
else:
    print(f"Detected {len(faces)} face(s).")
    for i, face in enumerate(faces):
        fa = face.get("facial_area", {})
        # Extract explicit keys (works regardless of key ordering)
        x = int(fa.get("x", 0))
        y = int(fa.get("y", 0))
        w = int(fa.get("w", 0))
        h = int(fa.get("h", 0))
        # Draw rectangle and label index
        cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)
        cv2.putText(img, f"Face {i+1}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)

    plt.figure(figsize=(6,6))
    plt.title("Detected Faces")
    plt.imshow(img)
    plt.axis("off")
    plt.show()

print("\n‚úÖ DONE.")